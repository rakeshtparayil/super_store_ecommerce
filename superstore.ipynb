{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sqlite3\n",
    "from tabulate import tabulate\n",
    "import psycopg2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# importing CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try different encodings\n",
    "try:\n",
    "    ecom = pd.read_csv('superstore.csv', encoding='utf-8')\n",
    "except UnicodeDecodeError:\n",
    "    # Try alternative encodings\n",
    "    ecom = pd.read_csv('superstore.csv', encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Row ID</th>\n",
       "      <th>Order ID</th>\n",
       "      <th>Order Date</th>\n",
       "      <th>Ship Date</th>\n",
       "      <th>Ship Mode</th>\n",
       "      <th>Customer ID</th>\n",
       "      <th>Customer Name</th>\n",
       "      <th>Segment</th>\n",
       "      <th>Country</th>\n",
       "      <th>City</th>\n",
       "      <th>...</th>\n",
       "      <th>Postal Code</th>\n",
       "      <th>Region</th>\n",
       "      <th>Product ID</th>\n",
       "      <th>Category</th>\n",
       "      <th>Sub-Category</th>\n",
       "      <th>Product Name</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Profit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>CA-2016-152156</td>\n",
       "      <td>11/8/2016</td>\n",
       "      <td>11/11/2016</td>\n",
       "      <td>Second Class</td>\n",
       "      <td>CG-12520</td>\n",
       "      <td>Claire Gute</td>\n",
       "      <td>Consumer</td>\n",
       "      <td>United States</td>\n",
       "      <td>Henderson</td>\n",
       "      <td>...</td>\n",
       "      <td>42420</td>\n",
       "      <td>South</td>\n",
       "      <td>FUR-BO-10001798</td>\n",
       "      <td>Furniture</td>\n",
       "      <td>Bookcases</td>\n",
       "      <td>Bush Somerset Collection Bookcase</td>\n",
       "      <td>261.9600</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>41.9136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>CA-2016-152156</td>\n",
       "      <td>11/8/2016</td>\n",
       "      <td>11/11/2016</td>\n",
       "      <td>Second Class</td>\n",
       "      <td>CG-12520</td>\n",
       "      <td>Claire Gute</td>\n",
       "      <td>Consumer</td>\n",
       "      <td>United States</td>\n",
       "      <td>Henderson</td>\n",
       "      <td>...</td>\n",
       "      <td>42420</td>\n",
       "      <td>South</td>\n",
       "      <td>FUR-CH-10000454</td>\n",
       "      <td>Furniture</td>\n",
       "      <td>Chairs</td>\n",
       "      <td>Hon Deluxe Fabric Upholstered Stacking Chairs,...</td>\n",
       "      <td>731.9400</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>219.5820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>CA-2016-138688</td>\n",
       "      <td>6/12/2016</td>\n",
       "      <td>6/16/2016</td>\n",
       "      <td>Second Class</td>\n",
       "      <td>DV-13045</td>\n",
       "      <td>Darrin Van Huff</td>\n",
       "      <td>Corporate</td>\n",
       "      <td>United States</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>...</td>\n",
       "      <td>90036</td>\n",
       "      <td>West</td>\n",
       "      <td>OFF-LA-10000240</td>\n",
       "      <td>Office Supplies</td>\n",
       "      <td>Labels</td>\n",
       "      <td>Self-Adhesive Address Labels for Typewriters b...</td>\n",
       "      <td>14.6200</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.8714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>US-2015-108966</td>\n",
       "      <td>10/11/2015</td>\n",
       "      <td>10/18/2015</td>\n",
       "      <td>Standard Class</td>\n",
       "      <td>SO-20335</td>\n",
       "      <td>Sean O'Donnell</td>\n",
       "      <td>Consumer</td>\n",
       "      <td>United States</td>\n",
       "      <td>Fort Lauderdale</td>\n",
       "      <td>...</td>\n",
       "      <td>33311</td>\n",
       "      <td>South</td>\n",
       "      <td>FUR-TA-10000577</td>\n",
       "      <td>Furniture</td>\n",
       "      <td>Tables</td>\n",
       "      <td>Bretford CR4500 Series Slim Rectangular Table</td>\n",
       "      <td>957.5775</td>\n",
       "      <td>5</td>\n",
       "      <td>0.45</td>\n",
       "      <td>-383.0310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>US-2015-108966</td>\n",
       "      <td>10/11/2015</td>\n",
       "      <td>10/18/2015</td>\n",
       "      <td>Standard Class</td>\n",
       "      <td>SO-20335</td>\n",
       "      <td>Sean O'Donnell</td>\n",
       "      <td>Consumer</td>\n",
       "      <td>United States</td>\n",
       "      <td>Fort Lauderdale</td>\n",
       "      <td>...</td>\n",
       "      <td>33311</td>\n",
       "      <td>South</td>\n",
       "      <td>OFF-ST-10000760</td>\n",
       "      <td>Office Supplies</td>\n",
       "      <td>Storage</td>\n",
       "      <td>Eldon Fold 'N Roll Cart System</td>\n",
       "      <td>22.3680</td>\n",
       "      <td>2</td>\n",
       "      <td>0.20</td>\n",
       "      <td>2.5164</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Row ID        Order ID  Order Date   Ship Date       Ship Mode Customer ID  \\\n",
       "0       1  CA-2016-152156   11/8/2016  11/11/2016    Second Class    CG-12520   \n",
       "1       2  CA-2016-152156   11/8/2016  11/11/2016    Second Class    CG-12520   \n",
       "2       3  CA-2016-138688   6/12/2016   6/16/2016    Second Class    DV-13045   \n",
       "3       4  US-2015-108966  10/11/2015  10/18/2015  Standard Class    SO-20335   \n",
       "4       5  US-2015-108966  10/11/2015  10/18/2015  Standard Class    SO-20335   \n",
       "\n",
       "     Customer Name    Segment        Country             City  ...  \\\n",
       "0      Claire Gute   Consumer  United States        Henderson  ...   \n",
       "1      Claire Gute   Consumer  United States        Henderson  ...   \n",
       "2  Darrin Van Huff  Corporate  United States      Los Angeles  ...   \n",
       "3   Sean O'Donnell   Consumer  United States  Fort Lauderdale  ...   \n",
       "4   Sean O'Donnell   Consumer  United States  Fort Lauderdale  ...   \n",
       "\n",
       "  Postal Code  Region       Product ID         Category Sub-Category  \\\n",
       "0       42420   South  FUR-BO-10001798        Furniture    Bookcases   \n",
       "1       42420   South  FUR-CH-10000454        Furniture       Chairs   \n",
       "2       90036    West  OFF-LA-10000240  Office Supplies       Labels   \n",
       "3       33311   South  FUR-TA-10000577        Furniture       Tables   \n",
       "4       33311   South  OFF-ST-10000760  Office Supplies      Storage   \n",
       "\n",
       "                                        Product Name     Sales  Quantity  \\\n",
       "0                  Bush Somerset Collection Bookcase  261.9600         2   \n",
       "1  Hon Deluxe Fabric Upholstered Stacking Chairs,...  731.9400         3   \n",
       "2  Self-Adhesive Address Labels for Typewriters b...   14.6200         2   \n",
       "3      Bretford CR4500 Series Slim Rectangular Table  957.5775         5   \n",
       "4                     Eldon Fold 'N Roll Cart System   22.3680         2   \n",
       "\n",
       "   Discount    Profit  \n",
       "0      0.00   41.9136  \n",
       "1      0.00  219.5820  \n",
       "2      0.00    6.8714  \n",
       "3      0.45 -383.0310  \n",
       "4      0.20    2.5164  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a copy of the dataset\n",
    "ecom_copy = ecom.copy()\n",
    "\n",
    "#display the first few rows of the copied dataset\n",
    "ecom_copy.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9994, 21)\n",
      "793\n",
      "row_id             int64\n",
      "order_id          object\n",
      "order_date        object\n",
      "ship_date         object\n",
      "ship_mode         object\n",
      "customer_id       object\n",
      "customer_name     object\n",
      "segment           object\n",
      "country           object\n",
      "city              object\n",
      "state             object\n",
      "postal_code        int64\n",
      "region            object\n",
      "product_id        object\n",
      "category          object\n",
      "sub-category      object\n",
      "product_name      object\n",
      "sales            float64\n",
      "quantity           int64\n",
      "discount         float64\n",
      "profit           float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "#change the column names to lowercase and replace spaces with underscores\n",
    "ecom_copy.columns = ecom_copy.columns.str.lower().str.replace(' ', '_')\n",
    "\n",
    "#display the first few rows of the dataset\n",
    "ecom_copy.head()\n",
    "\n",
    "# number of rows and columns in the dataset\n",
    "print(ecom_copy.shape)\n",
    "\n",
    "# number of unique customers in the dataset\n",
    "print(ecom_copy['customer_id'].nunique())\n",
    "\n",
    "#show the data types of the columns\n",
    "print(ecom_copy.dtypes)\n",
    "\n",
    "#drop row_id column\n",
    "ecom_copy.drop('row_id', axis=1, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting Column types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change the column types to the appropriate data types\n",
    "ecom_copy['order_date'] = pd.to_datetime(ecom_copy['order_date'])  # Already datetime64[ns]\n",
    "ecom_copy['ship_date'] = pd.to_datetime(ecom_copy['ship_date'])    # Already datetime64[ns]\n",
    "ecom_copy['customer_id'] = ecom_copy['customer_id'].astype('category')  # Change from object to category\n",
    "ecom_copy['product_id'] = ecom_copy['product_id'].astype('category')    # Change from object to category\n",
    "ecom_copy['category'] = ecom_copy['category'].astype('category')        # Change from object to category\n",
    "ecom_copy['product_name'] = ecom_copy['product_name'].astype(str)       # Keep as string (object)\n",
    "ecom_copy['sales'] = ecom_copy['sales'].astype(float)              # Already float64\n",
    "ecom_copy['quantity'] = ecom_copy['quantity'].astype(int)          # Already int64\n",
    "ecom_copy['discount'] = ecom_copy['discount'].astype(float)        # Already float64\n",
    "ecom_copy['profit'] = ecom_copy['profit'].astype(float)            # Already float64\n",
    "ecom_copy['customer_name'] = ecom_copy['customer_name'].astype('category')  # Change from object to category\n",
    "ecom_copy['segment'] = ecom_copy['segment'].astype('category')          # Change from object to category\n",
    "ecom_copy['city'] = ecom_copy['city'].astype('category')                # Change from object to category\n",
    "ecom_copy['state'] = ecom_copy['state'].astype('category')              # Change from object to category\n",
    "ecom_copy['country'] = ecom_copy['country'].astype('category')          # Change from object to category\n",
    "ecom_copy['region'] = ecom_copy['region'].astype('category')            # Change from object to category\n",
    "ecom_copy['order_id'] = ecom_copy['order_id'].astype('category')        # Change from object to category\n",
    "ecom_copy['ship_mode'] = ecom_copy['ship_mode'].astype('category')      # Change from object to category\n",
    "ecom_copy['postal_code'] = ecom_copy['postal_code'].astype(str)         # Change from int64 to string\n",
    "ecom_copy['sub-category'] = ecom_copy['sub-category'].astype('category')  # Change from object to category\n",
    "\n",
    "# Convert postal_code from object to category\n",
    "ecom_copy['postal_code'] = ecom_copy['postal_code'].astype('category')\n",
    "\n",
    "# Optionally convert product_name to category if there are many duplicates\n",
    "# First check the cardinality ratio\n",
    "product_name_ratio = ecom_copy['product_name'].nunique() / len(ecom_copy)\n",
    "if product_name_ratio < 0.5:  # If less than 50% unique values\n",
    "    ecom_copy['product_name'] = ecom_copy['product_name'].astype('category')\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9994 entries, 0 to 9993\n",
      "Data columns (total 20 columns):\n",
      " #   Column         Non-Null Count  Dtype         \n",
      "---  ------         --------------  -----         \n",
      " 0   order_id       9994 non-null   category      \n",
      " 1   order_date     9994 non-null   datetime64[ns]\n",
      " 2   ship_date      9994 non-null   datetime64[ns]\n",
      " 3   ship_mode      9994 non-null   category      \n",
      " 4   customer_id    9994 non-null   category      \n",
      " 5   customer_name  9994 non-null   category      \n",
      " 6   segment        9994 non-null   category      \n",
      " 7   country        9994 non-null   category      \n",
      " 8   city           9994 non-null   category      \n",
      " 9   state          9994 non-null   category      \n",
      " 10  postal_code    9994 non-null   category      \n",
      " 11  region         9994 non-null   category      \n",
      " 12  product_id     9994 non-null   category      \n",
      " 13  category       9994 non-null   category      \n",
      " 14  sub-category   9994 non-null   category      \n",
      " 15  product_name   9994 non-null   category      \n",
      " 16  sales          9994 non-null   float64       \n",
      " 17  quantity       9994 non-null   int64         \n",
      " 18  discount       9994 non-null   float64       \n",
      " 19  profit         9994 non-null   float64       \n",
      "dtypes: category(14), datetime64[ns](2), float64(3), int64(1)\n",
      "memory usage: 1.1 MB\n"
     ]
    }
   ],
   "source": [
    "ecom_copy.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Enginnering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enrich_ecom_data(df):\n",
    "    \"\"\"\n",
    "    Adds category, subcategory, segment, and region IDs to the DataFrame.\n",
    "    \n",
    "    Args:\n",
    "        df (pandas.DataFrame): Original DataFrame containing columns:\n",
    "                              'Product ID', 'Segment', 'Region'\n",
    "        \n",
    "    Returns:\n",
    "        pandas.DataFrame: Enriched DataFrame with ID columns\n",
    "    \"\"\"\n",
    "    # Create a copy to avoid modifying the original\n",
    "    result_df = df.copy()\n",
    "    \n",
    "    # 1. Extract category_id and subcategory_id from Product ID\n",
    "    result_df['category_id'] = result_df['product_id'].apply(\n",
    "        lambda x: x.split('-')[0] + '-' + x.split('-')[-1][:4]\n",
    "    )\n",
    "    \n",
    "    result_df['subcategory_id'] = result_df['product_id'].apply(\n",
    "        lambda x: x.split('-')[0] + '-' + x.split('-')[1] + '-' + x.split('-')[-1][:4]\n",
    "    )\n",
    "    \n",
    "    # 2. Define the segment ID mapping\n",
    "    segment_id_map = {\n",
    "        'Consumer': 'CONS-1000',\n",
    "        'Corporate': 'CORP-1000',\n",
    "        'Home Office': 'HOME-1000'\n",
    "    }\n",
    "    \n",
    "    # Add the segment_id column\n",
    "    result_df['segment_id'] = result_df['segment'].map(segment_id_map)\n",
    "    \n",
    "    # 3. Define the region ID mapping\n",
    "    region_id_map = {\n",
    "        'Central': 'CENT-1000',\n",
    "        'East': 'EAST-1000',\n",
    "        'South': 'SOUT-1000',\n",
    "        'West': 'WEST-1000'\n",
    "    }\n",
    "    \n",
    "    # Add the region_id column\n",
    "    result_df['region_id'] = result_df['region'].map(region_id_map)\n",
    "    \n",
    "    return result_df\n",
    "\n",
    "# Apply to your ecom_copy DataFrame\n",
    "ecom_copy = enrich_ecom_data(ecom_copy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Tables using SQLite "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_database_tables(db_name='ecom_v2.db'):\n",
    "    \"\"\"\n",
    "    Step 1: Creates tables in SQLite database without populating them.\n",
    "    \n",
    "    Args:\n",
    "        db_name (str): Name of the SQLite database file\n",
    "        \n",
    "    Returns:\n",
    "        sqlite3.Connection: The database connection\n",
    "    \"\"\"\n",
    "    # Connect to the database (creates it if it doesn't exist)\n",
    "    conn = sqlite3.connect(db_name)\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    print(f\"Creating database: {db_name}\")\n",
    "    \n",
    "    # 1. Lookup tables\n",
    "    print(\"Creating lookup tables...\")\n",
    "    \n",
    "    # Segments lookup table\n",
    "    cursor.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS segments (\n",
    "        segment_id TEXT PRIMARY KEY,\n",
    "        segment_name TEXT UNIQUE\n",
    "    )\n",
    "    ''')\n",
    "    \n",
    "    # Regions lookup table\n",
    "    cursor.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS regions (\n",
    "        region_id TEXT PRIMARY KEY,\n",
    "        region_name TEXT UNIQUE\n",
    "    )\n",
    "    ''')\n",
    "    \n",
    "    # Categories lookup table\n",
    "    cursor.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS categories (\n",
    "        category_id TEXT PRIMARY KEY,\n",
    "        category_name TEXT UNIQUE\n",
    "    )\n",
    "    ''')\n",
    "    \n",
    "    # Subcategories lookup table\n",
    "    cursor.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS subcategories (\n",
    "        subcategory_id TEXT PRIMARY KEY,\n",
    "        subcategory_name TEXT,\n",
    "        category_id TEXT,\n",
    "        FOREIGN KEY (category_id) REFERENCES categories (category_id)\n",
    "    )\n",
    "    ''')\n",
    "    \n",
    "    # 2. Main tables\n",
    "    print(\"Creating main tables...\")\n",
    "    \n",
    "    # Customers table\n",
    "    cursor.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS customers (\n",
    "        customer_id TEXT PRIMARY KEY,\n",
    "        customer_name TEXT,\n",
    "        segment_id TEXT,\n",
    "        country TEXT,\n",
    "        city TEXT,\n",
    "        state TEXT,\n",
    "        postal_code TEXT,\n",
    "        region_id TEXT,\n",
    "        FOREIGN KEY (segment_id) REFERENCES segments (segment_id),\n",
    "        FOREIGN KEY (region_id) REFERENCES regions (region_id)\n",
    "    )\n",
    "    ''')\n",
    "    \n",
    "    # Products table\n",
    "    cursor.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS products (\n",
    "        product_id TEXT PRIMARY KEY,\n",
    "        product_name TEXT,\n",
    "        category_id TEXT,\n",
    "        subcategory_id TEXT,\n",
    "        FOREIGN KEY (category_id) REFERENCES categories (category_id),\n",
    "        FOREIGN KEY (subcategory_id) REFERENCES subcategories (subcategory_id)\n",
    "    )\n",
    "    ''')\n",
    "    \n",
    "    # Orders table\n",
    "    cursor.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS orders (\n",
    "        order_id TEXT PRIMARY KEY,\n",
    "        order_date TEXT,\n",
    "        ship_date TEXT,\n",
    "        ship_mode TEXT,\n",
    "        customer_id TEXT,\n",
    "        FOREIGN KEY (customer_id) REFERENCES customers (customer_id)\n",
    "    )\n",
    "    ''')\n",
    "    \n",
    "    # Enhanced Order details table with feature engineering\n",
    "    cursor.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS order_details (\n",
    "        order_id TEXT,\n",
    "        product_id TEXT,\n",
    "        quantity INTEGER,\n",
    "        sales REAL,\n",
    "        discount REAL,\n",
    "        profit REAL,\n",
    "        \n",
    "        -- Feature engineered fields\n",
    "        unit_price REAL,\n",
    "        price_before_discount REAL,\n",
    "        discount_amount REAL,\n",
    "        cost_per_unit REAL,\n",
    "        margin_percentage REAL,\n",
    "        \n",
    "        PRIMARY KEY (order_id, product_id),\n",
    "        FOREIGN KEY (order_id) REFERENCES orders (order_id),\n",
    "        FOREIGN KEY (product_id) REFERENCES products (product_id)\n",
    "    )\n",
    "    ''')\n",
    "    \n",
    "    conn.commit()\n",
    "    print(f\"Tables created successfully in {db_name}\")\n",
    "    \n",
    "    return conn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Populating the database tables with data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_database_tables(conn, ecom_copy):\n",
    "    \"\"\"\n",
    "    Step 2: Populates the database tables with data from the enriched DataFrame.\n",
    "    \n",
    "    Args:\n",
    "        conn (sqlite3.Connection): The database connection\n",
    "        ecom_copy (pandas.DataFrame): Enriched DataFrame with the column names as shown\n",
    "        \n",
    "    Returns:\n",
    "        sqlite3.Connection: The database connection\n",
    "    \"\"\"\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    print(\"Populating database tables...\")\n",
    "    \n",
    "    # 1. Populate lookup tables\n",
    "    print(\"Populating lookup tables...\")\n",
    "    \n",
    "    # Segments\n",
    "    segments_df = ecom_copy[['segment_id', 'segment']].drop_duplicates()\n",
    "    for _, row in segments_df.iterrows():\n",
    "        cursor.execute(\n",
    "            \"INSERT OR IGNORE INTO segments (segment_id, segment_name) VALUES (?, ?)\",\n",
    "            (row['segment_id'], row['segment'])\n",
    "        )\n",
    "    \n",
    "    # Regions\n",
    "    regions_df = ecom_copy[['region_id', 'region']].drop_duplicates()\n",
    "    for _, row in regions_df.iterrows():\n",
    "        cursor.execute(\n",
    "            \"INSERT OR IGNORE INTO regions (region_id, region_name) VALUES (?, ?)\",\n",
    "            (row['region_id'], row['region'])\n",
    "        )\n",
    "    \n",
    "    # Categories\n",
    "    categories_df = ecom_copy[['category_id', 'category']].drop_duplicates()\n",
    "    for _, row in categories_df.iterrows():\n",
    "        cursor.execute(\n",
    "            \"INSERT OR IGNORE INTO categories (category_id, category_name) VALUES (?, ?)\",\n",
    "            (row['category_id'], row['category'])\n",
    "        )\n",
    "    \n",
    "    # Subcategories\n",
    "    subcategories_df = ecom_copy[['subcategory_id', 'sub-category', 'category_id']].drop_duplicates()\n",
    "    for _, row in subcategories_df.iterrows():\n",
    "        cursor.execute(\n",
    "            \"INSERT OR IGNORE INTO subcategories (subcategory_id, subcategory_name, category_id) VALUES (?, ?, ?)\",\n",
    "            (row['subcategory_id'], row['sub-category'], row['category_id'])\n",
    "        )\n",
    "    \n",
    "    # 2. Populate main tables\n",
    "    print(\"Populating main tables...\")\n",
    "    \n",
    "    # Customers\n",
    "    customers_df = ecom_copy[['customer_id', 'customer_name', 'segment_id', 'country', 'city', \n",
    "                       'state', 'postal_code', 'region_id']].drop_duplicates()\n",
    "    for _, row in customers_df.iterrows():\n",
    "        cursor.execute('''\n",
    "        INSERT OR IGNORE INTO customers \n",
    "        (customer_id, customer_name, segment_id, country, city, state, postal_code, region_id)\n",
    "        VALUES (?, ?, ?, ?, ?, ?, ?, ?)\n",
    "        ''', (row['customer_id'], row['customer_name'], row['segment_id'], row['country'], \n",
    "              row['city'], row['state'], row['postal_code'], row['region_id']))\n",
    "    \n",
    "    # Products\n",
    "    products_df = ecom_copy[['product_id', 'product_name', 'category_id', 'subcategory_id']].drop_duplicates()\n",
    "    for _, row in products_df.iterrows():\n",
    "        cursor.execute('''\n",
    "        INSERT OR IGNORE INTO products\n",
    "        (product_id, product_name, category_id, subcategory_id)\n",
    "        VALUES (?, ?, ?, ?)\n",
    "        ''', (row['product_id'], row['product_name'], row['category_id'], row['subcategory_id']))\n",
    "    \n",
    "    # Orders - Converting timestamps to strings to avoid SQLite binding errors\n",
    "    orders_df = ecom_copy[['order_id', 'order_date', 'ship_date', 'ship_mode', 'customer_id']].drop_duplicates()\n",
    "    for _, row in orders_df.iterrows():\n",
    "        # Convert timestamps to strings in ISO format\n",
    "        order_date_str = row['order_date'].strftime('%Y-%m-%d') if pd.notna(row['order_date']) else None\n",
    "        ship_date_str = row['ship_date'].strftime('%Y-%m-%d') if pd.notna(row['ship_date']) else None\n",
    "        \n",
    "        cursor.execute('''\n",
    "        INSERT OR IGNORE INTO orders\n",
    "        (order_id, order_date, ship_date, ship_mode, customer_id)\n",
    "        VALUES (?, ?, ?, ?, ?)\n",
    "        ''', (row['order_id'], order_date_str, ship_date_str, \n",
    "              row['ship_mode'], row['customer_id']))\n",
    "    \n",
    "    # Order details with feature engineering\n",
    "    for _, row in ecom_copy.iterrows():\n",
    "        # Handle edge cases\n",
    "        quantity = row['quantity'] if row['quantity'] > 0 else 1  # Avoid division by zero\n",
    "        sales = row['sales'] if row['sales'] != 0 else 0.01  # Avoid division by zero\n",
    "        discount = row['discount'] if 0 <= row['discount'] < 1 else 0  # Ensure discount is valid\n",
    "        \n",
    "        # Calculate derived metrics\n",
    "        unit_price = sales / quantity\n",
    "        price_before_discount = sales / (1 - discount) if discount < 1 else sales\n",
    "        discount_amount = price_before_discount - sales\n",
    "        cost = sales - row['profit']\n",
    "        cost_per_unit = cost / quantity\n",
    "        margin_percentage = (row['profit'] / sales) * 100 if sales > 0 else 0\n",
    "        \n",
    "        cursor.execute('''\n",
    "        INSERT OR IGNORE INTO order_details\n",
    "        (order_id, product_id, quantity, sales, discount, profit, \n",
    "         unit_price, price_before_discount, discount_amount, cost_per_unit, margin_percentage)\n",
    "        VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "        ''', (row['order_id'], row['product_id'], row['quantity'], \n",
    "              row['sales'], row['discount'], row['profit'],\n",
    "              round(unit_price, 2), round(price_before_discount, 2), \n",
    "              round(discount_amount, 2), round(cost_per_unit, 2), round(margin_percentage, 2)))\n",
    "    \n",
    "    # Commit changes\n",
    "    conn.commit()\n",
    "    print(\"Tables populated successfully\")\n",
    "    \n",
    "    return conn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the DB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verifying data population in ecom_v2.db...\n",
      "\n",
      "Table record counts:\n",
      "- segments: 3 records\n",
      "- regions: 4 records\n",
      "- categories: 3 records\n",
      "- subcategories: 17 records\n",
      "- customers: 793 records\n",
      "- products: 1862 records\n",
      "- orders: 5009 records\n",
      "- order_details: 9986 records\n",
      "\n",
      "Successfully joined all tables!\n",
      "\n",
      "Sample data from complete join:\n",
      "         order_id  order_date    customer_name segment_name region_name  \\\n",
      "0  CA-2016-152156  2016-11-08      Claire Gute     Consumer       South   \n",
      "1  CA-2016-152156  2016-11-08      Claire Gute     Consumer       South   \n",
      "2  CA-2016-138688  2016-06-12  Darrin Van Huff    Corporate        West   \n",
      "3  US-2015-108966  2015-10-11   Sean O'Donnell     Consumer       South   \n",
      "4  US-2015-108966  2015-10-11   Sean O'Donnell     Consumer       South   \n",
      "\n",
      "                                        product_name    category_name  \\\n",
      "0                  Bush Somerset Collection Bookcase        Furniture   \n",
      "1  Hon Deluxe Fabric Upholstered Stacking Chairs,...        Furniture   \n",
      "2  Self-Adhesive Address Labels for Typewriters b...  Office Supplies   \n",
      "3      Bretford CR4500 Series Slim Rectangular Table        Furniture   \n",
      "4                     Eldon Fold 'N Roll Cart System  Office Supplies   \n",
      "\n",
      "  subcategory_name  quantity     sales    profit  unit_price  \\\n",
      "0        Bookcases         2  261.9600   41.9136      130.98   \n",
      "1           Chairs         3  731.9400  219.5820      243.98   \n",
      "2           Labels         2   14.6200    6.8714        7.31   \n",
      "3           Tables         5  957.5775 -383.0310      191.52   \n",
      "4          Storage         2   22.3680    2.5164       11.18   \n",
      "\n",
      "   margin_percentage  \n",
      "0              16.00  \n",
      "1              30.00  \n",
      "2              47.00  \n",
      "3             -40.00  \n",
      "4              11.25  \n",
      "\n",
      "✅ Database verification complete: Data successfully populated across all tables\n",
      "\n",
      "Feature engineering verification:\n",
      "         order_id       product_id  quantity   sales  discount    profit  unit_price  price_before_discount  discount_amount  cost_per_unit  margin_percentage  calculated_unit_price  calculated_price_before_discount  calculated_discount_amount  calculated_cost_per_unit  calculated_margin_percentage\n",
      "0  CA-2016-152156  FUR-BO-10001798         2  261.96       0.0   41.9136      130.98                 261.96              0.0         110.02               16.0                 130.98                            261.96                         0.0                  110.0232                          16.0\n",
      "1  CA-2016-152156  FUR-CH-10000454         3  731.94       0.0  219.5820      243.98                 731.94              0.0         170.79               30.0                 243.98                            731.94                         0.0                  170.7860                          30.0\n",
      "2  CA-2016-138688  OFF-LA-10000240         2   14.62       0.0    6.8714        7.31                  14.62              0.0           3.87               47.0                   7.31                             14.62                         0.0                    3.8743                          47.0\n",
      "\n",
      "✅ Feature engineering calculations verified correctly\n",
      "\n",
      "Database connection closed.\n"
     ]
    }
   ],
   "source": [
    "def verify_database_population(db_name='ecom_v2.db'):\n",
    "    \"\"\"\n",
    "    Runs a simple query to verify data was properly populated across all main tables.\n",
    "    \n",
    "    Args:\n",
    "        db_name (str): Name of the SQLite database file\n",
    "    \"\"\"\n",
    "    conn = sqlite3.connect(db_name)\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    print(f\"Verifying data population in {db_name}...\")\n",
    "    \n",
    "    # 1. Check record counts in all tables\n",
    "    tables = ['segments', 'regions', 'categories', 'subcategories', \n",
    "              'customers', 'products', 'orders', 'order_details']\n",
    "    \n",
    "    print(\"\\nTable record counts:\")\n",
    "    for table in tables:\n",
    "        cursor.execute(f\"SELECT COUNT(*) FROM {table}\")\n",
    "        count = cursor.fetchone()[0]\n",
    "        print(f\"- {table}: {count} records\")\n",
    "    \n",
    "    # 2. Run a simple join across all tables to verify relationships\n",
    "    query = \"\"\"\n",
    "    SELECT \n",
    "        o.order_id,\n",
    "        o.order_date,\n",
    "        c.customer_name,\n",
    "        s.segment_name,\n",
    "        r.region_name,\n",
    "        p.product_name,\n",
    "        cat.category_name,\n",
    "        subcat.subcategory_name,\n",
    "        od.quantity,\n",
    "        od.sales,\n",
    "        od.profit,\n",
    "        od.unit_price,\n",
    "        od.margin_percentage\n",
    "    FROM order_details od\n",
    "    JOIN orders o ON od.order_id = o.order_id\n",
    "    JOIN customers c ON o.customer_id = c.customer_id\n",
    "    JOIN segments s ON c.segment_id = s.segment_id\n",
    "    JOIN regions r ON c.region_id = r.region_id\n",
    "    JOIN products p ON od.product_id = p.product_id\n",
    "    JOIN categories cat ON p.category_id = cat.category_id\n",
    "    JOIN subcategories subcat ON p.subcategory_id = subcat.subcategory_id\n",
    "    LIMIT 5\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        results = pd.read_sql_query(query, conn)\n",
    "        print(\"\\nSuccessfully joined all tables!\")\n",
    "        print(\"\\nSample data from complete join:\")\n",
    "        print(results)\n",
    "        \n",
    "        if len(results) > 0:\n",
    "            print(\"\\n✅ Database verification complete: Data successfully populated across all tables\")\n",
    "        else:\n",
    "            print(\"\\n❌ Database verification failed: Join query returned no results\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"\\n❌ Database verification failed: {str(e)}\")\n",
    "    \n",
    "    # 3. Extra verification: Check feature-engineered fields calculation\n",
    "    verification_query = \"\"\"\n",
    "    SELECT\n",
    "        od.order_id,\n",
    "        od.product_id,\n",
    "        od.quantity,\n",
    "        od.sales,\n",
    "        od.discount,\n",
    "        od.profit,\n",
    "        od.unit_price,\n",
    "        od.price_before_discount,\n",
    "        od.discount_amount,\n",
    "        od.cost_per_unit,\n",
    "        od.margin_percentage,\n",
    "        -- Verify calculations are correct\n",
    "        (od.sales / od.quantity) AS calculated_unit_price,\n",
    "        (od.sales / (1 - od.discount)) AS calculated_price_before_discount,\n",
    "        ((od.sales / (1 - od.discount)) - od.sales) AS calculated_discount_amount,\n",
    "        ((od.sales - od.profit) / od.quantity) AS calculated_cost_per_unit,\n",
    "        ((od.profit / od.sales) * 100) AS calculated_margin_percentage\n",
    "    FROM order_details od\n",
    "    WHERE od.quantity > 0 \n",
    "      AND od.sales > 0\n",
    "      AND od.discount < 1\n",
    "    LIMIT 3\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        verification_results = pd.read_sql_query(verification_query, conn)\n",
    "        print(\"\\nFeature engineering verification:\")\n",
    "        \n",
    "        with pd.option_context('display.max_columns', None, 'display.width', 1000):\n",
    "            print(verification_results)\n",
    "            \n",
    "        # Calculate discrepancies\n",
    "        if len(verification_results) > 0:\n",
    "            discrepancies = []\n",
    "            \n",
    "            for col in ['unit_price', 'price_before_discount', 'discount_amount', 'cost_per_unit', 'margin_percentage']:\n",
    "                calc_col = f'calculated_{col}'\n",
    "                # Check if values are within 0.01 of each other (account for rounding differences)\n",
    "                diff = abs(verification_results[col] - verification_results[calc_col]).max()\n",
    "                if diff > 0.01:\n",
    "                    discrepancies.append(f\"{col} (max diff: {diff:.4f})\")\n",
    "            \n",
    "            if discrepancies:\n",
    "                print(f\"\\n⚠️ Feature engineering discrepancies found in: {', '.join(discrepancies)}\")\n",
    "            else:\n",
    "                print(\"\\n✅ Feature engineering calculations verified correctly\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n❌ Feature engineering verification failed: {str(e)}\")\n",
    "    \n",
    "    conn.close()\n",
    "    print(\"\\nDatabase connection closed.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Run the verification\n",
    "    verify_database_population()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------------+--------------+-------------+----------------+---------------+\n",
      "|    | order_id       | order_date   | ship_date   | ship_mode      | customer_id   |\n",
      "|----+----------------+--------------+-------------+----------------+---------------|\n",
      "|  0 | CA-2016-152156 | 2016-11-08   | 2016-11-11  | Second Class   | CG-12520      |\n",
      "|  1 | CA-2016-138688 | 2016-06-12   | 2016-06-16  | Second Class   | DV-13045      |\n",
      "|  2 | US-2015-108966 | 2015-10-11   | 2015-10-18  | Standard Class | SO-20335      |\n",
      "|  3 | CA-2014-115812 | 2014-06-09   | 2014-06-14  | Standard Class | BH-11710      |\n",
      "|  4 | CA-2017-114412 | 2017-04-15   | 2017-04-20  | Standard Class | AA-10480      |\n",
      "+----+----------------+--------------+-------------+----------------+---------------+\n",
      "+----+---------------+-----------------+--------------+---------------+-----------------+----------------+---------------+-------------+\n",
      "|    | customer_id   | customer_name   | segment_id   | country       | city            | state          |   postal_code | region_id   |\n",
      "|----+---------------+-----------------+--------------+---------------+-----------------+----------------+---------------+-------------|\n",
      "|  0 | CG-12520      | Claire Gute     | CONS-1000    | United States | Henderson       | Kentucky       |         42420 | SOUT-1000   |\n",
      "|  1 | DV-13045      | Darrin Van Huff | CORP-1000    | United States | Los Angeles     | California     |         90036 | WEST-1000   |\n",
      "|  2 | SO-20335      | Sean O'Donnell  | CONS-1000    | United States | Fort Lauderdale | Florida        |         33311 | SOUT-1000   |\n",
      "|  3 | BH-11710      | Brosina Hoffman | CONS-1000    | United States | Los Angeles     | California     |         90032 | WEST-1000   |\n",
      "|  4 | AA-10480      | Andrew Allen    | CONS-1000    | United States | Concord         | North Carolina |         28027 | SOUT-1000   |\n",
      "+----+---------------+-----------------+--------------+---------------+-----------------+----------------+---------------+-------------+\n",
      "+----+-----------------+-------------------------------------------------------------+---------------+------------------+\n",
      "|    | product_id      | product_name                                                | category_id   | subcategory_id   |\n",
      "|----+-----------------+-------------------------------------------------------------+---------------+------------------|\n",
      "|  0 | FUR-BO-10001798 | Bush Somerset Collection Bookcase                           | FUR-1000      | FUR-BO-1000      |\n",
      "|  1 | FUR-CH-10000454 | Hon Deluxe Fabric Upholstered Stacking Chairs, Rounded Back | FUR-1000      | FUR-CH-1000      |\n",
      "|  2 | OFF-LA-10000240 | Self-Adhesive Address Labels for Typewriters by Universal   | OFF-1000      | OFF-LA-1000      |\n",
      "|  3 | FUR-TA-10000577 | Bretford CR4500 Series Slim Rectangular Table               | FUR-1000      | FUR-TA-1000      |\n",
      "|  4 | OFF-ST-10000760 | Eldon Fold 'N Roll Cart System                              | OFF-1000      | OFF-ST-1000      |\n",
      "+----+-----------------+-------------------------------------------------------------+---------------+------------------+\n",
      "+----+----------------+-----------------+------------+---------+------------+-----------+--------------+-------------------------+-------------------+-----------------+---------------------+\n",
      "|    | order_id       | product_id      |   quantity |   sales |   discount |    profit |   unit_price |   price_before_discount |   discount_amount |   cost_per_unit |   margin_percentage |\n",
      "|----+----------------+-----------------+------------+---------+------------+-----------+--------------+-------------------------+-------------------+-----------------+---------------------|\n",
      "|  0 | CA-2016-152156 | FUR-BO-10001798 |          2 | 261.96  |       0    |   41.9136 |       130.98 |                  261.96 |              0    |          110.02 |               16    |\n",
      "|  1 | CA-2016-152156 | FUR-CH-10000454 |          3 | 731.94  |       0    |  219.582  |       243.98 |                  731.94 |              0    |          170.79 |               30    |\n",
      "|  2 | CA-2016-138688 | OFF-LA-10000240 |          2 |  14.62  |       0    |    6.8714 |         7.31 |                   14.62 |              0    |            3.87 |               47    |\n",
      "|  3 | US-2015-108966 | FUR-TA-10000577 |          5 | 957.577 |       0.45 | -383.031  |       191.52 |                 1741.05 |            783.47 |          268.12 |              -40    |\n",
      "|  4 | US-2015-108966 | OFF-ST-10000760 |          2 |  22.368 |       0.2  |    2.5164 |        11.18 |                   27.96 |              5.59 |            9.93 |               11.25 |\n",
      "+----+----------------+-----------------+------------+---------+------------+-----------+--------------+-------------------------+-------------------+-----------------+---------------------+\n",
      "+----+---------------+-----------------+\n",
      "|    | category_id   | category_name   |\n",
      "|----+---------------+-----------------|\n",
      "|  0 | FUR-1000      | Furniture       |\n",
      "|  1 | OFF-1000      | Office Supplies |\n",
      "|  2 | TEC-1000      | Technology      |\n",
      "+----+---------------+-----------------+\n",
      "+----+------------------+--------------------+---------------+\n",
      "|    | subcategory_id   | subcategory_name   | category_id   |\n",
      "|----+------------------+--------------------+---------------|\n",
      "|  0 | FUR-BO-1000      | Bookcases          | FUR-1000      |\n",
      "|  1 | FUR-CH-1000      | Chairs             | FUR-1000      |\n",
      "|  2 | OFF-LA-1000      | Labels             | OFF-1000      |\n",
      "|  3 | FUR-TA-1000      | Tables             | FUR-1000      |\n",
      "|  4 | OFF-ST-1000      | Storage            | OFF-1000      |\n",
      "+----+------------------+--------------------+---------------+\n",
      "+----+--------------+----------------+\n",
      "|    | segment_id   | segment_name   |\n",
      "|----+--------------+----------------|\n",
      "|  0 | CONS-1000    | Consumer       |\n",
      "|  1 | CORP-1000    | Corporate      |\n",
      "|  2 | HOME-1000    | Home Office    |\n",
      "+----+--------------+----------------+\n",
      "+----+-------------+---------------+\n",
      "|    | region_id   | region_name   |\n",
      "|----+-------------+---------------|\n",
      "|  0 | SOUT-1000   | South         |\n",
      "|  1 | WEST-1000   | West          |\n",
      "|  2 | CENT-1000   | Central       |\n",
      "|  3 | EAST-1000   | East          |\n",
      "+----+-------------+---------------+\n"
     ]
    }
   ],
   "source": [
    "# Reopen the connection\n",
    "conn = sqlite3.connect('ecom_v2.db')\n",
    "\n",
    "# Load individual tables\n",
    "orders_df = pd.read_sql(\"SELECT * FROM orders\", conn)\n",
    "customers_df = pd.read_sql(\"SELECT * FROM customers\", conn)\n",
    "products_df = pd.read_sql(\"SELECT * FROM products\", conn)\n",
    "order_details_df = pd.read_sql(\"SELECT * FROM order_details\", conn)\n",
    "categories_df = pd.read_sql(\"SELECT * FROM categories\", conn)\n",
    "subcategories_df = pd.read_sql(\"SELECT * FROM subcategories\", conn)\n",
    "segments_df = pd.read_sql(\"SELECT * FROM segments\", conn)\n",
    "regions_df = pd.read_sql(\"SELECT * FROM regions\", conn)\n",
    "\n",
    "print(tabulate(orders_df.head(), headers='keys', tablefmt='psql'))\n",
    "print(tabulate(customers_df.head(), headers='keys', tablefmt='psql'))\n",
    "print(tabulate(products_df.head(), headers='keys', tablefmt='psql'))\n",
    "print(tabulate(order_details_df.head(), headers='keys', tablefmt='psql'))\n",
    "print(tabulate(categories_df.head(), headers='keys', tablefmt='psql'))\n",
    "print(tabulate(subcategories_df.head(), headers='keys', tablefmt='psql'))\n",
    "print(tabulate(segments_df.head(), headers='keys', tablefmt='psql'))\n",
    "print(tabulate(regions_df.head(), headers='keys', tablefmt='psql'))\n",
    "\n",
    "\n",
    "# Close the connection\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "order_id             category\n",
      "order_date     datetime64[ns]\n",
      "ship_date      datetime64[ns]\n",
      "ship_mode            category\n",
      "customer_id          category\n",
      "dtype: object\n",
      "customer_id      category\n",
      "customer_name      object\n",
      "segment_id       category\n",
      "country          category\n",
      "city             category\n",
      "state            category\n",
      "postal_code        object\n",
      "region_id          object\n",
      "dtype: object\n",
      "product_id        category\n",
      "product_name        object\n",
      "category_id       category\n",
      "subcategory_id    category\n",
      "dtype: object\n",
      "order_id                 category\n",
      "product_id               category\n",
      "quantity                    int64\n",
      "sales                     float64\n",
      "discount                  float64\n",
      "profit                    float64\n",
      "unit_price                float64\n",
      "price_before_discount     float64\n",
      "discount_amount           float64\n",
      "cost_per_unit             float64\n",
      "margin_percentage         float64\n",
      "dtype: object\n",
      "category_id      category\n",
      "category_name      object\n",
      "dtype: object\n",
      "subcategory_id      category\n",
      "subcategory_name      object\n",
      "category_id         category\n",
      "dtype: object\n",
      "segment_id      category\n",
      "segment_name      object\n",
      "dtype: object\n",
      "region_id      category\n",
      "region_name      object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "#convert all the tables columns data types to the appropriate data types\n",
    "\n",
    "# Convert orders_df columns to appropriate data types\n",
    "orders_df['order_date'] = pd.to_datetime(orders_df['order_date'])\n",
    "orders_df['ship_date'] = pd.to_datetime(orders_df['ship_date'])\n",
    "orders_df['order_id'] = orders_df['order_id'].astype('category')\n",
    "orders_df['ship_mode'] = orders_df['ship_mode'].astype('category')\n",
    "orders_df['customer_id'] = orders_df['customer_id'].astype('category')\n",
    "\n",
    "# Convert customers_df columns to appropriate data types\n",
    "customers_df['customer_id'] = customers_df['customer_id'].astype('category')\n",
    "customers_df['customer_name'] = customers_df['customer_name'].astype(str)\n",
    "customers_df['segment_id'] = customers_df['segment_id'].astype('category')\n",
    "customers_df['country'] = customers_df['country'].astype('category')\n",
    "customers_df['city'] = customers_df['city'].astype('category')\n",
    "customers_df['state'] = customers_df['state'].astype('category')\n",
    "\n",
    "# Convert products_df columns to appropriate data types\n",
    "products_df['product_id'] = products_df['product_id'].astype('category')\n",
    "products_df['product_name'] = products_df['product_name'].astype(str)\n",
    "products_df['category_id'] = products_df['category_id'].astype('category')\n",
    "products_df['subcategory_id'] = products_df['subcategory_id'].astype('category')\n",
    "\n",
    "# Convert categories_df columns to appropriate data types\n",
    "categories_df['category_id'] = categories_df['category_id'].astype('category')\n",
    "categories_df['category_name'] = categories_df['category_name'].astype(str)\n",
    "\n",
    "# Convert subcategories_df columns to appropriate data types\n",
    "subcategories_df['subcategory_id'] = subcategories_df['subcategory_id'].astype('category')\n",
    "subcategories_df['subcategory_name'] = subcategories_df['subcategory_name'].astype(str)\n",
    "subcategories_df['category_id'] = subcategories_df['category_id'].astype('category')\n",
    "\n",
    "# Convert segments_df columns to appropriate data types\n",
    "segments_df['segment_id'] = segments_df['segment_id'].astype('category')\n",
    "segments_df['segment_name'] = segments_df['segment_name'].astype(str)\n",
    "\n",
    "# Convert regions_df columns to appropriate data types\n",
    "regions_df['region_id'] = regions_df['region_id'].astype('category')\n",
    "regions_df['region_name'] = regions_df['region_name'].astype(str)\n",
    "\n",
    "#convert the order_details_df columns to the appropriate data types\n",
    "order_details_df['order_id'] = order_details_df['order_id'].astype('category')\n",
    "order_details_df['product_id'] = order_details_df['product_id'].astype('category')\n",
    "order_details_df['quantity'] = order_details_df['quantity'].astype(int)\n",
    "order_details_df['sales'] = order_details_df['sales'].astype(float)\n",
    "order_details_df['discount'] = order_details_df['discount'].astype(float)\n",
    "order_details_df['profit'] = order_details_df['profit'].astype(float)\n",
    "order_details_df['unit_price'] = order_details_df['unit_price'].astype(float)\n",
    "order_details_df['price_before_discount'] = order_details_df['price_before_discount'].astype(float)\n",
    "order_details_df['discount_amount'] = order_details_df['discount_amount'].astype(float)\n",
    "order_details_df['cost_per_unit'] = order_details_df['cost_per_unit'].astype(float)\n",
    "order_details_df['margin_percentage'] = order_details_df['margin_percentage'].astype(float)\n",
    "\n",
    "\n",
    "# Display the data types of the columns\n",
    "print(orders_df.dtypes)\n",
    "print(customers_df.dtypes)\n",
    "print(products_df.dtypes)\n",
    "print(order_details_df.dtypes)\n",
    "print(categories_df.dtypes)\n",
    "print(subcategories_df.dtypes)\n",
    "print(segments_df.dtypes)\n",
    "print(regions_df.dtypes)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CAB_V1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
