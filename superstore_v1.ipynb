{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sqlite3\n",
    "from tabulate import tabulate\n",
    "import psycopg2\n",
    "import sqlalchemy as sa\n",
    "from sqlalchemy import create_engine, Column, Integer, String, Float, Date, ForeignKey, MetaData, Table, inspect, text,Numeric\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy.orm import sessionmaker, relationship\n",
    "from datetime import datetime\n",
    "from decimal import Decimal\n",
    "import psycopg2\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSV Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try different encodings\n",
    "try:\n",
    "    ecom = pd.read_csv('superstore.csv', encoding='utf-8')\n",
    "except UnicodeDecodeError:\n",
    "    # Try alternative encodings\n",
    "    ecom = pd.read_csv('superstore.csv', encoding='latin-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making a copy of DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a copy of the dataframe\n",
    "ecom_new = ecom.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Enginnering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change the column names to lowercase and replace spaces with underscores\n",
    "ecom_new.columns = ecom_new.columns.str.lower().str.replace(' ', '_')\n",
    "\n",
    "#drop the columns that are not needed\n",
    "ecom_new.drop(columns=['row_id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new columns such as category_id and sub_category_id from product_id \n",
    "ecom_new[\"category_id\"] = ecom_new[\"category\"].apply(lambda x: x[:3].upper() + \"-1000\")\n",
    "ecom_new[\"subcategory_id\"] = ecom_new.apply(lambda row: f\"{row['category'][:3].upper()}-{row['sub-category'][:2].upper()}-1000\", axis=1)\n",
    "\n",
    "#create a column unit price for product\n",
    "ecom_new[\"unit_price\"] = ecom_new[\"sales\"] / ecom_new[\"quantity\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>order_date</th>\n",
       "      <th>ship_date</th>\n",
       "      <th>ship_mode</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>customer_name</th>\n",
       "      <th>segment</th>\n",
       "      <th>country</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>...</th>\n",
       "      <th>category</th>\n",
       "      <th>sub-category</th>\n",
       "      <th>product_name</th>\n",
       "      <th>sales</th>\n",
       "      <th>quantity</th>\n",
       "      <th>discount</th>\n",
       "      <th>profit</th>\n",
       "      <th>category_id</th>\n",
       "      <th>subcategory_id</th>\n",
       "      <th>unit_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CA-2016-152156</td>\n",
       "      <td>11/8/2016</td>\n",
       "      <td>11/11/2016</td>\n",
       "      <td>Second Class</td>\n",
       "      <td>CG-12520</td>\n",
       "      <td>Claire Gute</td>\n",
       "      <td>Consumer</td>\n",
       "      <td>United States</td>\n",
       "      <td>Henderson</td>\n",
       "      <td>Kentucky</td>\n",
       "      <td>...</td>\n",
       "      <td>Furniture</td>\n",
       "      <td>Bookcases</td>\n",
       "      <td>Bush Somerset Collection Bookcase</td>\n",
       "      <td>261.9600</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>41.9136</td>\n",
       "      <td>FUR-1000</td>\n",
       "      <td>FUR-BO-1000</td>\n",
       "      <td>130.9800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CA-2016-152156</td>\n",
       "      <td>11/8/2016</td>\n",
       "      <td>11/11/2016</td>\n",
       "      <td>Second Class</td>\n",
       "      <td>CG-12520</td>\n",
       "      <td>Claire Gute</td>\n",
       "      <td>Consumer</td>\n",
       "      <td>United States</td>\n",
       "      <td>Henderson</td>\n",
       "      <td>Kentucky</td>\n",
       "      <td>...</td>\n",
       "      <td>Furniture</td>\n",
       "      <td>Chairs</td>\n",
       "      <td>Hon Deluxe Fabric Upholstered Stacking Chairs,...</td>\n",
       "      <td>731.9400</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>219.5820</td>\n",
       "      <td>FUR-1000</td>\n",
       "      <td>FUR-CH-1000</td>\n",
       "      <td>243.9800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CA-2016-138688</td>\n",
       "      <td>6/12/2016</td>\n",
       "      <td>6/16/2016</td>\n",
       "      <td>Second Class</td>\n",
       "      <td>DV-13045</td>\n",
       "      <td>Darrin Van Huff</td>\n",
       "      <td>Corporate</td>\n",
       "      <td>United States</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>California</td>\n",
       "      <td>...</td>\n",
       "      <td>Office Supplies</td>\n",
       "      <td>Labels</td>\n",
       "      <td>Self-Adhesive Address Labels for Typewriters b...</td>\n",
       "      <td>14.6200</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.8714</td>\n",
       "      <td>OFF-1000</td>\n",
       "      <td>OFF-LA-1000</td>\n",
       "      <td>7.3100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US-2015-108966</td>\n",
       "      <td>10/11/2015</td>\n",
       "      <td>10/18/2015</td>\n",
       "      <td>Standard Class</td>\n",
       "      <td>SO-20335</td>\n",
       "      <td>Sean O'Donnell</td>\n",
       "      <td>Consumer</td>\n",
       "      <td>United States</td>\n",
       "      <td>Fort Lauderdale</td>\n",
       "      <td>Florida</td>\n",
       "      <td>...</td>\n",
       "      <td>Furniture</td>\n",
       "      <td>Tables</td>\n",
       "      <td>Bretford CR4500 Series Slim Rectangular Table</td>\n",
       "      <td>957.5775</td>\n",
       "      <td>5</td>\n",
       "      <td>0.45</td>\n",
       "      <td>-383.0310</td>\n",
       "      <td>FUR-1000</td>\n",
       "      <td>FUR-TA-1000</td>\n",
       "      <td>191.5155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>US-2015-108966</td>\n",
       "      <td>10/11/2015</td>\n",
       "      <td>10/18/2015</td>\n",
       "      <td>Standard Class</td>\n",
       "      <td>SO-20335</td>\n",
       "      <td>Sean O'Donnell</td>\n",
       "      <td>Consumer</td>\n",
       "      <td>United States</td>\n",
       "      <td>Fort Lauderdale</td>\n",
       "      <td>Florida</td>\n",
       "      <td>...</td>\n",
       "      <td>Office Supplies</td>\n",
       "      <td>Storage</td>\n",
       "      <td>Eldon Fold 'N Roll Cart System</td>\n",
       "      <td>22.3680</td>\n",
       "      <td>2</td>\n",
       "      <td>0.20</td>\n",
       "      <td>2.5164</td>\n",
       "      <td>OFF-1000</td>\n",
       "      <td>OFF-ST-1000</td>\n",
       "      <td>11.1840</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         order_id  order_date   ship_date       ship_mode customer_id  \\\n",
       "0  CA-2016-152156   11/8/2016  11/11/2016    Second Class    CG-12520   \n",
       "1  CA-2016-152156   11/8/2016  11/11/2016    Second Class    CG-12520   \n",
       "2  CA-2016-138688   6/12/2016   6/16/2016    Second Class    DV-13045   \n",
       "3  US-2015-108966  10/11/2015  10/18/2015  Standard Class    SO-20335   \n",
       "4  US-2015-108966  10/11/2015  10/18/2015  Standard Class    SO-20335   \n",
       "\n",
       "     customer_name    segment        country             city       state  \\\n",
       "0      Claire Gute   Consumer  United States        Henderson    Kentucky   \n",
       "1      Claire Gute   Consumer  United States        Henderson    Kentucky   \n",
       "2  Darrin Van Huff  Corporate  United States      Los Angeles  California   \n",
       "3   Sean O'Donnell   Consumer  United States  Fort Lauderdale     Florida   \n",
       "4   Sean O'Donnell   Consumer  United States  Fort Lauderdale     Florida   \n",
       "\n",
       "   ...         category sub-category  \\\n",
       "0  ...        Furniture    Bookcases   \n",
       "1  ...        Furniture       Chairs   \n",
       "2  ...  Office Supplies       Labels   \n",
       "3  ...        Furniture       Tables   \n",
       "4  ...  Office Supplies      Storage   \n",
       "\n",
       "                                        product_name     sales quantity  \\\n",
       "0                  Bush Somerset Collection Bookcase  261.9600        2   \n",
       "1  Hon Deluxe Fabric Upholstered Stacking Chairs,...  731.9400        3   \n",
       "2  Self-Adhesive Address Labels for Typewriters b...   14.6200        2   \n",
       "3      Bretford CR4500 Series Slim Rectangular Table  957.5775        5   \n",
       "4                     Eldon Fold 'N Roll Cart System   22.3680        2   \n",
       "\n",
       "  discount    profit  category_id  subcategory_id  unit_price  \n",
       "0     0.00   41.9136     FUR-1000     FUR-BO-1000    130.9800  \n",
       "1     0.00  219.5820     FUR-1000     FUR-CH-1000    243.9800  \n",
       "2     0.00    6.8714     OFF-1000     OFF-LA-1000      7.3100  \n",
       "3     0.45 -383.0310     FUR-1000     FUR-TA-1000    191.5155  \n",
       "4     0.20    2.5164     OFF-1000     OFF-ST-1000     11.1840  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ecom_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_normalized_database(df, connection_string):\n",
    "    \"\"\"\n",
    "    Create a normalized database using the actual columns in the DataFrame\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas.DataFrame\n",
    "        DataFrame with e-commerce data\n",
    "    connection_string : str\n",
    "        SQLAlchemy connection string for database connection\n",
    "    \"\"\"\n",
    "    # Print column names to debug\n",
    "    print(\"Available columns in DataFrame:\", df.columns.tolist())\n",
    "    \n",
    "    # Create database engine\n",
    "    engine = create_engine(connection_string, echo=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop existing tables to start fresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop any existing tables\n",
    "drop_tables_sql = \"\"\"\n",
    "    DROP TABLE IF EXISTS order_details CASCADE;\n",
    "    DROP TABLE IF EXISTS orders CASCADE;\n",
    "    DROP TABLE IF EXISTS products CASCADE;\n",
    "    DROP TABLE IF EXISTS customers CASCADE;\n",
    "    DROP TABLE IF EXISTS segments CASCADE;\n",
    "    DROP TABLE IF EXISTS regions CASCADE;\n",
    "    \"\"\"\n",
    "    \n",
    "with engine.begin() as conn:\n",
    "        conn.execute(text(drop_tables_sql))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create new tables with proper schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tables with schema matching the diagram\n",
    "create_tables_sql = \"\"\"\n",
    "    -- Create regions table\n",
    "    CREATE TABLE regions (\n",
    "        region_id INTEGER PRIMARY KEY,\n",
    "        region VARCHAR(50) NOT NULL\n",
    "    );\n",
    "\n",
    "    -- Create segments table\n",
    "    CREATE TABLE segments (\n",
    "        segment_id INTEGER PRIMARY KEY,\n",
    "        segment VARCHAR(50) NOT NULL\n",
    "    );\n",
    "\n",
    "    -- Create customers table\n",
    "    CREATE TABLE customers (\n",
    "        customer_id VARCHAR(50) PRIMARY KEY,\n",
    "        customer_name VARCHAR(100) NOT NULL,\n",
    "        segment_id INTEGER REFERENCES segments(segment_id),\n",
    "        country VARCHAR(50),\n",
    "        city VARCHAR(100),\n",
    "        state VARCHAR(50),\n",
    "        postal_code VARCHAR(20),\n",
    "        region_id INTEGER REFERENCES regions(region_id)\n",
    "    );\n",
    "\n",
    "    -- Create products table\n",
    "    CREATE TABLE products (\n",
    "        product_id VARCHAR(50) PRIMARY KEY,\n",
    "        product_name VARCHAR(255) NOT NULL,\n",
    "        base_price DECIMAL(10, 2),\n",
    "        category_id INTEGER,\n",
    "        category VARCHAR(50),\n",
    "        subcategory_id INTEGER,\n",
    "        subcategory VARCHAR(50)\n",
    "    );\n",
    "\n",
    "    -- Create orders table\n",
    "    CREATE TABLE orders (\n",
    "        order_id VARCHAR(50) PRIMARY KEY,\n",
    "        order_date DATE NOT NULL,\n",
    "        ship_date DATE,\n",
    "        ship_mode VARCHAR(50),\n",
    "        customer_id VARCHAR(50) REFERENCES customers(customer_id)\n",
    "    );\n",
    "\n",
    "    -- Create order_details table\n",
    "    CREATE TABLE order_details (\n",
    "        order_id VARCHAR(50) REFERENCES orders(order_id),\n",
    "        product_id VARCHAR(50) REFERENCES products(product_id),\n",
    "        quantity INTEGER NOT NULL,\n",
    "        discount DECIMAL(5, 2),\n",
    "        sales DECIMAL(10, 2),\n",
    "        profit DECIMAL(10, 2),\n",
    "        PRIMARY KEY (order_id, product_id)\n",
    "    );\n",
    "    \"\"\"\n",
    "    \n",
    "    # Execute each statement separately for better error handling\n",
    "with engine.begin() as conn:\n",
    "        for stmt in create_tables_sql.split(';'):\n",
    "            if stmt.strip():\n",
    "                conn.execute(text(stmt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract reference data for lookup tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create regions table\n",
    "regions_df = ecom_new[['region']].drop_duplicates().reset_index(drop=True)\n",
    "regions_df['region_id'] = regions_df.index + 1  # Create sequential IDs\n",
    "\t\n",
    "# Create segments table\n",
    "segments_df = ecom_new[['segment']].drop_duplicates().reset_index(drop=True)\n",
    "segments_df['segment_id'] = segments_df.index + 1  # Create sequential IDs\n",
    "\t\n",
    "# Create mapping dictionaries\n",
    "region_id_map = dict(zip(regions_df['region'], regions_df['region_id']))\n",
    "segment_id_map = dict(zip(segments_df['segment'], segments_df['segment_id']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare customers table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create customers table\n",
    "customers_df = ecom_new[['customer_id', 'customer_name', 'segment', \n",
    "                'country', 'city', 'state', 'postal_code', 'region']].drop_duplicates('customer_id')\n",
    "    \n",
    "# Map segment and region to IDs\n",
    "customers_df['segment_id'] = customers_df['segment'].map(segment_id_map)\n",
    "customers_df['region_id'] = customers_df['region'].map(region_id_map)\n",
    "    \n",
    "# Remove redundant columns\n",
    "customers_df = customers_df.drop(['segment', 'region'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare products table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check which product columns actually exist\n",
    "product_cols = ['product_id', 'product_name', 'category_id', 'category', 'subcategory_id']\n",
    "    \n",
    "# Check for subcategory column variants\n",
    "if 'subcategory' in ecom_new.columns:\n",
    "    product_cols.append('subcategory')\n",
    "elif 'sub-category' in ecom_new.columns:\n",
    "    product_cols.append('sub-category')\n",
    "    \n",
    "# Check for price column variants\n",
    "if 'base_price' in ecom_new.columns:\n",
    "    product_cols.append('base_price')\n",
    "elif 'unit_price' in ecom_new.columns:\n",
    "    product_cols.append('unit_price')\n",
    "        \n",
    "# Get available product columns\n",
    "available_product_cols = [col for col in product_cols if col in ecom_new.columns]\n",
    "products_df = ecom_new[available_product_cols].drop_duplicates('product_id')\n",
    "    \n",
    "# Rename columns if needed for database schema\n",
    "rename_map = {}\n",
    "if 'sub-category' in products_df.columns:\n",
    "    rename_map['sub-category'] = 'subcategory'\n",
    "if 'unit_price' in products_df.columns and 'base_price' not in products_df.columns:\n",
    "    rename_map['unit_price'] = 'base_price'\n",
    "\n",
    "if rename_map:\n",
    "    products_df = products_df.rename(columns=rename_map)\n",
    "\n",
    "# Convert category_id and subcategory_id to integers by extracting numeric parts if they're strings\n",
    "for col in ['category_id', 'subcategory_id']:\n",
    "    if col in products_df.columns and products_df[col].dtype == 'object':\n",
    "        try:\n",
    "            products_df[col] = products_df[col].str.extract(r'(\\d+)').astype(int)\n",
    "        except:\n",
    "            pass  # If conversion fails, keep as string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare orders and order_details tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8 duplicate order_id/product_id combinations. Aggregating...\n"
     ]
    }
   ],
   "source": [
    "# Create orders table\n",
    "orders_df = ecom_new[['order_id', 'order_date', 'ship_date', \n",
    "                   'ship_mode', 'customer_id']].drop_duplicates('order_id')\n",
    "\n",
    "# Convert date columns to datetime\n",
    "orders_df['order_date'] = pd.to_datetime(orders_df['order_date'])\n",
    "orders_df['ship_date'] = pd.to_datetime(orders_df['ship_date'])\n",
    "\n",
    "# Create order_details table\n",
    "order_details_df = ecom_new[['order_id', 'product_id', 'quantity', \n",
    "                          'discount', 'sales', 'profit']]\n",
    "\n",
    "# Check for duplicates in order_details\n",
    "duplicate_count = order_details_df.duplicated(['order_id', 'product_id']).sum()\n",
    "if duplicate_count > 0:\n",
    "    print(f\"Found {duplicate_count} duplicate order_id/product_id combinations. Aggregating...\")\n",
    "    \n",
    "    # Aggregate duplicates\n",
    "    order_details_df = order_details_df.groupby(['order_id', 'product_id']).agg({\n",
    "        'quantity': 'sum',\n",
    "        'discount': 'mean',\n",
    "        'sales': 'sum',\n",
    "        'profit': 'sum'\n",
    "    }).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data to the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "986"
      ]
     },
     "execution_count": 464,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import data in the correct order to satisfy foreign key constraints\n",
    "regions_df.to_sql('regions', engine, if_exists='append', index=False)\n",
    "segments_df.to_sql('segments', engine, if_exists='append', index=False)\n",
    "customers_df.to_sql('customers', engine, if_exists='append', index=False)\n",
    "products_df.to_sql('products', engine, if_exists='append', index=False)\n",
    "orders_df.to_sql('orders', engine, if_exists='append', index=False)\n",
    "order_details_df.to_sql('order_details', engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display sample data from each table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 5 rows from regions table ===\n",
      "region_id, region\n",
      "1, South\n",
      "2, West\n",
      "3, Central\n",
      "4, East\n",
      "\n",
      "=== 5 rows from segments table ===\n",
      "segment_id, segment\n",
      "1, Consumer\n",
      "2, Corporate\n",
      "3, Home Office\n",
      "\n",
      "=== 5 rows from customers table ===\n",
      "customer_id, customer_name, segment_id, country, city, state, postal_code, region_id\n",
      "CG-12520, Claire Gute, 1, United States, Henderson, Kentucky, 42420, 1\n",
      "DV-13045, Darrin Van Huff, 2, United States, Los Angeles, California, 90036, 2\n",
      "SO-20335, Sean O'Donnell, 1, United States, Fort Lauderdale, Florida, 33311, 1\n",
      "BH-11710, Brosina Hoffman, 1, United States, Los Angeles, California, 90032, 2\n",
      "AA-10480, Andrew Allen, 1, United States, Concord, North Carolina, 28027, 1\n",
      "\n",
      "=== 5 rows from products table ===\n",
      "product_id, product_name, base_price, category_id, category, subcategory_id, subcategory\n",
      "FUR-BO-10001798, Bush Somerset Collection Bookcase, 130.98, 1000, Furniture, 1000, Bookcases\n",
      "FUR-CH-10000454, Hon Deluxe Fabric Upholstered Stacking Chairs, Rounded Back, 243.98, 1000, Furniture, 1000, Chairs\n",
      "OFF-LA-10000240, Self-Adhesive Address Labels for Typewriters by Universal, 7.31, 1000, Office Supplies, 1000, Labels\n",
      "FUR-TA-10000577, Bretford CR4500 Series Slim Rectangular Table, 191.52, 1000, Furniture, 1000, Tables\n",
      "OFF-ST-10000760, Eldon Fold 'N Roll Cart System, 11.18, 1000, Office Supplies, 1000, Storage\n",
      "\n",
      "=== 5 rows from orders table ===\n",
      "order_id, order_date, ship_date, ship_mode, customer_id\n",
      "CA-2016-152156, 2016-11-08, 2016-11-11, Second Class, CG-12520\n",
      "CA-2016-138688, 2016-06-12, 2016-06-16, Second Class, DV-13045\n",
      "US-2015-108966, 2015-10-11, 2015-10-18, Standard Class, SO-20335\n",
      "CA-2014-115812, 2014-06-09, 2014-06-14, Standard Class, BH-11710\n",
      "CA-2017-114412, 2017-04-15, 2017-04-20, Standard Class, AA-10480\n",
      "\n",
      "=== 5 rows from order_details table ===\n",
      "order_id, product_id, quantity, discount, sales, profit\n",
      "CA-2014-100006, TEC-PH-10002075, 3, 0.0, 377.97, 109.61\n",
      "CA-2014-100090, FUR-TA-10003715, 3, 0.2, 502.49, -87.94\n",
      "CA-2014-100090, OFF-BI-10001597, 6, 0.2, 196.7, 68.85\n",
      "CA-2014-100293, OFF-PA-10000176, 6, 0.2, 91.06, 31.87\n",
      "CA-2014-100328, OFF-BI-10000343, 1, 0.2, 3.93, 1.33\n",
      "\n",
      "Database creation and population complete!\n"
     ]
    }
   ],
   "source": [
    "# Print 5 rows from each table to verify import\n",
    "table_names = ['regions', 'segments', 'customers', 'products', 'orders', 'order_details']\n",
    "    \n",
    "for table in table_names:\n",
    "        print(f\"\\n=== 5 rows from {table} table ===\")\n",
    "        try:\n",
    "            query = f\"SELECT * FROM {table} LIMIT 5;\"\n",
    "            result = pd.read_sql(query, engine)\n",
    "            \n",
    "            if len(result) > 0:\n",
    "                print(\", \".join(result.columns))\n",
    "                for _, row in result.iterrows():\n",
    "                    print(\", \".join(str(val) for val in row.values))\n",
    "            else:\n",
    "                print(f\"No data in {table} table\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error querying {table}: {str(e)}\")\n",
    "    \n",
    "print(\"\\nDatabase creation and population complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Call the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available columns in DataFrame: ['order_id', 'order_date', 'ship_date', 'ship_mode', 'customer_id', 'customer_name', 'segment', 'country', 'city', 'state', 'postal_code', 'region', 'product_id', 'category', 'sub-category', 'product_name', 'sales', 'quantity', 'discount', 'profit', 'category_id', 'subcategory_id', 'unit_price']\n"
     ]
    }
   ],
   "source": [
    "# Load your data\n",
    "# df = pd.read_csv('your_data.csv')  # or however you load your data\n",
    "\n",
    "# Create the normalized database\n",
    "create_normalized_database(ecom_new, 'postgresql://postgres:postgres@localhost:5432/superstore_v6')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CAB_V1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
